{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be61ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras.metrics\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from MLscores import calc_metrics, metrics_dict, cmvals, recall, hybridrecall\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "from check_and_prepare_dataset import load_dataset, prepare_dataset\n",
    "from manage_model import create_NN_model, create_sklearn_model, allowgrowthgpus\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "654c7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params={'ES_mindelta': 0.001, 'ES_monitor': 'loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 10}, 'dropout': 0.1, 'feature_drop': ('dir_max', 'dom_dir', 'month', 'wkd'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 70}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "#params={'ES_mindelta': 0.0001, 'ES_monitor': 'loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': 0.3, 'feature_drop': ('dir_max', 'dom_dir', 'month', 'wkd'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 200.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params = {}\n",
    "params['nn_auc']= {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_gr1', 'corine_gr2', 'corine_gr3', 'corine_gr4', 'corine_gr5', 'corine_gr6', 'corine_gr7', 'corine_gr8', 'corine_gr9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params['nn_h1'] = {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 2}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'corine_gr1', 'corine_gr2', 'corine_gr3', 'corine_gr4', 'corine_gr5', 'corine_gr6', 'corine_gr7', 'corine_gr8', 'corine_gr9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 60.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params['nn_h2'] = {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_gr1', 'corine_gr2', 'corine_gr3', 'corine_gr4', 'corine_gr5', 'corine_gr6', 'corine_gr7', 'corine_gr8', 'corine_gr9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params['nn_nh2'] = {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_1', 'corine_2', 'corine_3', 'corine_4', 'corine_5', 'corine_6', 'corine_7', 'corine_8', 'corine_9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 1700.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params['nn_nh5'] = {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 10}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_1', 'corine_2', 'corine_3', 'corine_4', 'corine_5', 'corine_6', 'corine_7', 'corine_8', 'corine_9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 1100.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c93e4a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'pop', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222130/3430584326.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222130/3430584326.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'pop', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222130/3430584326.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_corine_36', 'bin_dir_max_7', 'bin_month_5', 'bin_corine_30', 'bin_dir_max_3', 'bin_corine_23', 'bin_weekday_4', 'bin_corine_35', 'bin_corine_11', 'bin_corine_3', 'bin_corine_10', 'bin_weekday_2', 'bin_dom_dir_7', 'bin_corine_25', 'bin_dir_max_4', 'bin_corine_5', 'bin_corine_33', 'bin_corine_17', 'bin_corine_31', 'bin_corine_21', 'bin_corine_18', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_24', 'bin_corine_41', 'bin_corine_29', 'bin_corine_16', 'bin_corine_20', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_corine_8', 'bin_dom_dir_4', 'bin_corine_28', 'bin_dom_dir_3', 'bin_corine_4', 'bin_month_9', 'bin_corine_9', 'bin_dom_dir_5', 'bin_corine_40', 'bin_corine_7', 'bin_month_8', 'bin_corine_6', 'bin_month_4', 'bin_corine_27', 'bin_dir_max_1', 'bin_corine_12', 'bin_month_3', 'bin_corine_44', 'bin_corine_15', 'bin_weekday_7', 'bin_weekday_1', 'bin_corine_1', 'bin_dom_dir_1', 'bin_weekday_6', 'bin_month_6', 'bin_month_7', 'bin_corine_13', 'bin_weekday_5', 'bin_corine_32', 'pop', 'bin_weekday_3', 'bin_corine_43', 'bin_corine_42', 'bin_corine_14', 'bin_corine_26', 'bin_corine_37', 'bin_corine_19', 'bin_dir_max_5', 'bin_corine_2', 'bin_corine_38', 'bin_corine_22']\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222130/3430584326.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_corine_36', 'bin_dir_max_7', 'bin_month_5', 'bin_corine_30', 'bin_dir_max_3', 'bin_corine_23', 'bin_weekday_4', 'bin_corine_35', 'bin_corine_11', 'bin_corine_3', 'bin_corine_10', 'bin_weekday_2', 'bin_dom_dir_7', 'bin_corine_25', 'bin_dir_max_4', 'bin_corine_5', 'bin_corine_33', 'bin_corine_17', 'bin_corine_31', 'bin_corine_21', 'bin_corine_18', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_24', 'bin_corine_41', 'bin_corine_29', 'bin_corine_16', 'bin_corine_20', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_corine_8', 'bin_dom_dir_4', 'bin_corine_28', 'bin_dom_dir_3', 'bin_corine_4', 'bin_month_9', 'bin_corine_9', 'bin_dom_dir_5', 'bin_corine_40', 'bin_corine_7', 'bin_month_8', 'bin_corine_6', 'bin_month_4', 'bin_corine_27', 'bin_dir_max_1', 'bin_corine_12', 'bin_month_3', 'bin_corine_44', 'bin_corine_15', 'bin_weekday_7', 'bin_weekday_1', 'bin_corine_1', 'bin_dom_dir_1', 'bin_weekday_6', 'bin_month_6', 'bin_month_7', 'bin_corine_13', 'bin_weekday_5', 'bin_corine_32', 'pop', 'bin_weekday_3', 'bin_corine_43', 'bin_corine_42', 'bin_corine_14', 'bin_corine_26', 'bin_corine_37', 'bin_corine_19', 'bin_dir_max_5', 'bin_corine_2', 'bin_corine_38', 'bin_corine_22']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3222130/3430584326.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n"
     ]
    }
   ],
   "source": [
    "models={}\n",
    "for paramset in params:\n",
    "    X, y, g=load_dataset('/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv', \\\n",
    "                         params[paramset]['feature_drop'])\n",
    "    creatennmodel = partial(create_NN_model, params[paramset], X)\n",
    "    models[paramset]={}\n",
    "    models[paramset]['model'] = KerasClassifier(build_fn=creatennmodel, batch_size=params[paramset]['batch_size'], epochs=300, verbose=0,)\n",
    "    models[paramset]['params'] = params[paramset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a065493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_corine_36', 'bin_dir_max_7', 'bin_month_5', 'bin_corine_30', 'bin_dir_max_3', 'bin_corine_23', 'bin_weekday_4', 'bin_corine_35', 'bin_corine_11', 'bin_corine_3', 'bin_corine_10', 'bin_weekday_2', 'bin_dom_dir_7', 'bin_corine_25', 'bin_dir_max_4', 'bin_corine_5', 'bin_corine_33', 'bin_corine_17', 'bin_corine_31', 'bin_corine_21', 'bin_corine_18', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_24', 'bin_corine_41', 'bin_corine_29', 'bin_corine_16', 'bin_corine_20', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_corine_8', 'bin_dom_dir_4', 'bin_corine_28', 'bin_dom_dir_3', 'bin_corine_4', 'bin_month_9', 'bin_corine_9', 'bin_dom_dir_5', 'bin_corine_40', 'bin_corine_7', 'bin_month_8', 'bin_corine_6', 'bin_month_4', 'bin_corine_27', 'bin_dir_max_1', 'bin_corine_12', 'bin_month_3', 'bin_corine_44', 'bin_corine_15', 'bin_weekday_7', 'bin_weekday_1', 'bin_corine_1', 'bin_dom_dir_1', 'bin_weekday_6', 'bin_month_6', 'bin_month_7', 'bin_corine_13', 'bin_weekday_5', 'bin_corine_32', 'pop', 'bin_weekday_3', 'bin_corine_43', 'bin_corine_42', 'bin_corine_14', 'bin_corine_26', 'bin_corine_37', 'bin_corine_19', 'bin_dir_max_5', 'bin_corine_2', 'bin_corine_38', 'bin_corine_22']\n",
      "XT\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_corine_36', 'bin_dir_max_7', 'bin_month_5', 'bin_corine_30', 'bin_dir_max_3', 'bin_corine_23', 'bin_weekday_4', 'bin_corine_35', 'bin_corine_11', 'bin_corine_3', 'bin_corine_10', 'bin_weekday_2', 'bin_dom_dir_7', 'bin_corine_25', 'bin_dir_max_4', 'bin_corine_5', 'bin_corine_33', 'bin_corine_17', 'bin_corine_31', 'bin_corine_21', 'bin_corine_18', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_24', 'bin_corine_41', 'bin_corine_29', 'bin_corine_16', 'bin_corine_20', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_corine_8', 'bin_dom_dir_4', 'bin_corine_28', 'bin_dom_dir_3', 'bin_corine_4', 'bin_month_9', 'bin_corine_9', 'bin_dom_dir_5', 'bin_corine_40', 'bin_corine_7', 'bin_month_8', 'bin_corine_6', 'bin_month_4', 'bin_corine_27', 'bin_dir_max_1', 'bin_corine_12', 'bin_month_3', 'bin_corine_44', 'bin_corine_15', 'bin_weekday_7', 'bin_weekday_1', 'bin_corine_1', 'bin_dom_dir_1', 'bin_weekday_6', 'bin_month_6', 'bin_month_7', 'bin_corine_13', 'bin_weekday_5', 'bin_corine_32', 'pop', 'bin_weekday_3', 'bin_corine_43', 'bin_corine_42', 'bin_corine_14', 'bin_corine_26', 'bin_corine_37', 'bin_corine_19', 'bin_dir_max_5', 'bin_corine_2', 'bin_corine_38', 'bin_corine_22']\n",
      "XGB\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_corine_36', 'bin_dir_max_7', 'bin_month_5', 'bin_corine_30', 'bin_dir_max_3', 'bin_corine_23', 'bin_weekday_4', 'bin_corine_35', 'bin_corine_11', 'bin_corine_3', 'bin_corine_10', 'bin_weekday_2', 'bin_dom_dir_7', 'bin_corine_25', 'bin_dir_max_4', 'bin_corine_5', 'bin_corine_33', 'bin_corine_17', 'bin_corine_31', 'bin_corine_21', 'bin_corine_18', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_24', 'bin_corine_41', 'bin_corine_29', 'bin_corine_16', 'bin_corine_20', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_corine_8', 'bin_dom_dir_4', 'bin_corine_28', 'bin_dom_dir_3', 'bin_corine_4', 'bin_month_9', 'bin_corine_9', 'bin_dom_dir_5', 'bin_corine_40', 'bin_corine_7', 'bin_month_8', 'bin_corine_6', 'bin_month_4', 'bin_corine_27', 'bin_dir_max_1', 'bin_corine_12', 'bin_month_3', 'bin_corine_44', 'bin_corine_15', 'bin_weekday_7', 'bin_weekday_1', 'bin_corine_1', 'bin_dom_dir_1', 'bin_weekday_6', 'bin_month_6', 'bin_month_7', 'bin_corine_13', 'bin_weekday_5', 'bin_corine_32', 'pop', 'bin_weekday_3', 'bin_corine_43', 'bin_corine_42', 'bin_corine_14', 'bin_corine_26', 'bin_corine_37', 'bin_corine_19', 'bin_dir_max_5', 'bin_corine_2', 'bin_corine_38', 'bin_corine_22']\n"
     ]
    }
   ],
   "source": [
    "paramssk={}\n",
    "#RF best\n",
    "paramssk['RF']={'algo': 'RF','bootstrap': True, 'class_weights': {0: 1, 1: 10}, 'criterion': 'entropy', 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'corine_1', 'corine_2', 'corine_3', 'corine_4', 'corine_5', 'corine_6', 'corine_7', 'corine_8', 'corine_9'), 'max_depth': 1000, 'max_features': 2.0, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 350}\n",
    "#ET best\n",
    "paramssk['ET']={'algo': 'XT', 'bootstrap': True, 'class_weights': {0: 1, 1: 1}, 'criterion': 'entropy', 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'corine_1', 'corine_2', 'corine_3', 'corine_4', 'corine_5', 'corine_6', 'corine_7', 'corine_8', 'corine_9'), 'max_depth': None, 'max_features': 2.0, 'min_samples_leaf': 50, 'min_samples_split': 150, 'n_estimators': 800}\n",
    "#XG\n",
    "paramssk['XGB']={'algo': 'XGB', 'alpha': 60, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'corine_1', 'corine_2', 'corine_3', 'corine_4', 'corine_5', 'corine_6', 'corine_7', 'corine_8', 'corine_9'), 'gamma': 0.1, 'lambda': 21.0, 'max_depth': 44.0, 'n_estimators': 640, 'scale_pos_weight': 15, 'subsample': 0.6}\n",
    "for skalgo in paramssk:\n",
    "    print(paramssk[skalgo]['algo'])\n",
    "    X, y, g=load_dataset('/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv', \\\n",
    "                         params[paramset]['feature_drop'])\n",
    "    models[skalgo]={}\n",
    "    models[skalgo]['model'] = create_sklearn_model(paramssk[skalgo],X)\n",
    "    models[skalgo]['params']=paramssk[skalgo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0ed3408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_auc': {'model': <keras.wrappers.scikit_learn.KerasClassifier at 0x7f2b05119f30>,\n",
       "  'params': {'ES_mindelta': 0.002,\n",
       "   'ES_monitor': 'val_loss',\n",
       "   'ES_patience': 10,\n",
       "   'batch_size': 512,\n",
       "   'class_weights': {0: 1, 1: 5},\n",
       "   'dropout': None,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'pop',\n",
       "    'corine_gr1',\n",
       "    'corine_gr2',\n",
       "    'corine_gr3',\n",
       "    'corine_gr4',\n",
       "    'corine_gr5',\n",
       "    'corine_gr6',\n",
       "    'corine_gr7',\n",
       "    'corine_gr8',\n",
       "    'corine_gr9'),\n",
       "   'max_epochs': 2000,\n",
       "   'metric': 'accuracy',\n",
       "   'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}),\n",
       "   'optimizer': {'adam_params': None, 'name': 'Adam'}}},\n",
       " 'nn_h1': {'model': <keras.wrappers.scikit_learn.KerasClassifier at 0x7f2a105a44c0>,\n",
       "  'params': {'ES_mindelta': 0.002,\n",
       "   'ES_monitor': 'val_loss',\n",
       "   'ES_patience': 10,\n",
       "   'batch_size': 512,\n",
       "   'class_weights': {0: 1, 1: 2},\n",
       "   'dropout': None,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'corine_gr1',\n",
       "    'corine_gr2',\n",
       "    'corine_gr3',\n",
       "    'corine_gr4',\n",
       "    'corine_gr5',\n",
       "    'corine_gr6',\n",
       "    'corine_gr7',\n",
       "    'corine_gr8',\n",
       "    'corine_gr9'),\n",
       "   'max_epochs': 2000,\n",
       "   'metric': 'accuracy',\n",
       "   'n_internal_layers': (0, {'layer_1_0_nodes': 60.0}),\n",
       "   'optimizer': {'adam_params': None, 'name': 'Adam'}}},\n",
       " 'nn_h2': {'model': <keras.wrappers.scikit_learn.KerasClassifier at 0x7f2a005f78e0>,\n",
       "  'params': {'ES_mindelta': 0.002,\n",
       "   'ES_monitor': 'val_loss',\n",
       "   'ES_patience': 10,\n",
       "   'batch_size': 512,\n",
       "   'class_weights': {0: 1, 1: 5},\n",
       "   'dropout': None,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'pop',\n",
       "    'corine_gr1',\n",
       "    'corine_gr2',\n",
       "    'corine_gr3',\n",
       "    'corine_gr4',\n",
       "    'corine_gr5',\n",
       "    'corine_gr6',\n",
       "    'corine_gr7',\n",
       "    'corine_gr8',\n",
       "    'corine_gr9'),\n",
       "   'max_epochs': 2000,\n",
       "   'metric': 'accuracy',\n",
       "   'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}),\n",
       "   'optimizer': {'adam_params': None, 'name': 'Adam'}}},\n",
       " 'nn_nh2': {'model': <keras.wrappers.scikit_learn.KerasClassifier at 0x7f2a2810c370>,\n",
       "  'params': {'ES_mindelta': 0.002,\n",
       "   'ES_monitor': 'val_loss',\n",
       "   'ES_patience': 10,\n",
       "   'batch_size': 512,\n",
       "   'class_weights': {0: 1, 1: 5},\n",
       "   'dropout': None,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'pop',\n",
       "    'corine_1',\n",
       "    'corine_2',\n",
       "    'corine_3',\n",
       "    'corine_4',\n",
       "    'corine_5',\n",
       "    'corine_6',\n",
       "    'corine_7',\n",
       "    'corine_8',\n",
       "    'corine_9'),\n",
       "   'max_epochs': 2000,\n",
       "   'metric': 'accuracy',\n",
       "   'n_internal_layers': (0, {'layer_1_0_nodes': 1700.0}),\n",
       "   'optimizer': {'adam_params': None, 'name': 'Adam'}}},\n",
       " 'nn_nh5': {'model': <keras.wrappers.scikit_learn.KerasClassifier at 0x7f2a961a2fb0>,\n",
       "  'params': {'ES_mindelta': 0.002,\n",
       "   'ES_monitor': 'val_loss',\n",
       "   'ES_patience': 10,\n",
       "   'batch_size': 512,\n",
       "   'class_weights': {0: 1, 1: 10},\n",
       "   'dropout': None,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'pop',\n",
       "    'corine_1',\n",
       "    'corine_2',\n",
       "    'corine_3',\n",
       "    'corine_4',\n",
       "    'corine_5',\n",
       "    'corine_6',\n",
       "    'corine_7',\n",
       "    'corine_8',\n",
       "    'corine_9'),\n",
       "   'max_epochs': 2000,\n",
       "   'metric': 'accuracy',\n",
       "   'n_internal_layers': (0, {'layer_1_0_nodes': 1100.0}),\n",
       "   'optimizer': {'adam_params': None, 'name': 'Adam'}}},\n",
       " 'RF': {'model': RandomForestClassifier(class_weight={0: 1, 1: 10}, criterion='entropy',\n",
       "                         max_depth=1000, max_features=6, min_samples_leaf=10,\n",
       "                         n_estimators=350, n_jobs=8),\n",
       "  'params': {'algo': 'RF',\n",
       "   'bootstrap': True,\n",
       "   'class_weights': {0: 1, 1: 10},\n",
       "   'criterion': 'entropy',\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'corine_1',\n",
       "    'corine_2',\n",
       "    'corine_3',\n",
       "    'corine_4',\n",
       "    'corine_5',\n",
       "    'corine_6',\n",
       "    'corine_7',\n",
       "    'corine_8',\n",
       "    'corine_9'),\n",
       "   'max_depth': 1000,\n",
       "   'max_features': 2.0,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 350}},\n",
       " 'ET': {'model': ExtraTreesClassifier(bootstrap=True, class_weight={0: 1, 1: 1},\n",
       "                       criterion='entropy', max_features=6, min_samples_leaf=50,\n",
       "                       min_samples_split=150, n_estimators=800, n_jobs=8),\n",
       "  'params': {'algo': 'XT',\n",
       "   'bootstrap': True,\n",
       "   'class_weights': {0: 1, 1: 1},\n",
       "   'criterion': 'entropy',\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'corine_1',\n",
       "    'corine_2',\n",
       "    'corine_3',\n",
       "    'corine_4',\n",
       "    'corine_5',\n",
       "    'corine_6',\n",
       "    'corine_7',\n",
       "    'corine_8',\n",
       "    'corine_9'),\n",
       "   'max_depth': None,\n",
       "   'max_features': 2.0,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 150,\n",
       "   'n_estimators': 800}},\n",
       " 'XGB': {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=44, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=640, n_jobs=8, num_parallel_tree=None,\n",
       "                predictor=None, random_state=None, ...),\n",
       "  'params': {'algo': 'XGB',\n",
       "   'alpha': 60,\n",
       "   'feature_drop': ('month',\n",
       "    'weekday',\n",
       "    'dom_dir',\n",
       "    'dir_max',\n",
       "    'corine_1',\n",
       "    'corine_2',\n",
       "    'corine_3',\n",
       "    'corine_4',\n",
       "    'corine_5',\n",
       "    'corine_6',\n",
       "    'corine_7',\n",
       "    'corine_8',\n",
       "    'corine_9'),\n",
       "   'gamma': 0.1,\n",
       "   'lambda': 21.0,\n",
       "   'max_depth': 44.0,\n",
       "   'n_estimators': 640,\n",
       "   'scale_pos_weight': 15,\n",
       "   'subsample': 0.6}}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a54238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'pop', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n",
      "nn_auc\n"
     ]
    }
   ],
   "source": [
    "#models1={'RF':models['RF'], 'ET':models['ET']}\n",
    "#allowgrowthgpus()\n",
    "for modname in models:\n",
    "    X, y, g=load_dataset('/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv', \\\n",
    "                         models[modname]['params']['feature_drop'])\n",
    "    print(modname)\n",
    "    models[modname]['model'].fit(X,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3735e470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_auc\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'pop', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, {'model': <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f2b05119f30>, 'params': {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_gr1', 'corine_gr2', 'corine_gr3', 'corine_gr4', 'corine_gr5', 'corine_gr6', 'corine_gr7', 'corine_gr8', 'corine_gr9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}} was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#models[modname].fit(X,y)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X, y, g\u001b[38;5;241m=\u001b[39mload_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m      6\u001b[0m                          models[modname][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_drop\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m r\u001b[38;5;241m=\u001b[39m\u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m results_lists[modname]\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mimportances_mean\u001b[38;5;241m.\u001b[39margsort()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlfires_classic/lib/python3.10/site-packages/sklearn/inspection/_permutation_importance.py:252\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    250\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m scoring\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scoring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 252\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     scorers_dict \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(estimator, scoring)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlfires_classic/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:460\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator should be an estimator implementing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m estimator\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, {'model': <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f2b05119f30>, 'params': {'ES_mindelta': 0.002, 'ES_monitor': 'val_loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': None, 'feature_drop': ('month', 'weekday', 'dom_dir', 'dir_max', 'pop', 'corine_gr1', 'corine_gr2', 'corine_gr3', 'corine_gr4', 'corine_gr5', 'corine_gr6', 'corine_gr7', 'corine_gr8', 'corine_gr9'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 700.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}} was passed"
     ]
    }
   ],
   "source": [
    "results_lists={}\n",
    "for modname in models:\n",
    "    print(modname)\n",
    "    #models[modname].fit(X,y)\n",
    "    X, y, g=load_dataset('/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv', \\\n",
    "                             models[modname]['params']['feature_drop'])\n",
    "    r=permutation_importance(models[modname], X, y, n_repeats=3,random_state=0, scoring='roc_auc')\n",
    "    results_lists[modname]=[]\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        #if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        if not any(c in X.columns[i] for c in ['dir_max','dom_dir','wkd','month']):\n",
    "            results_dict={}\n",
    "            results_dict['rank '+modname]=X.columns[i]\n",
    "            results_dict['perm. imp.'+modname]=r.importances_mean[i]\n",
    "            results_lists[modname]+=[results_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf604fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bin_corine_14', 'bin_corine_gr1', 'bin_corine_44', 'bin_corine_7',\n",
       "       'bin_corine_18', 'bin_corine_41', 'bin_corine_gr32', 'max_temp',\n",
       "       'dom_vel', 'bin_corine_5',\n",
       "       ...\n",
       "       'bin_month_8', 'bin_month_9', 'bin_month_10', 'bin_weekday_1',\n",
       "       'bin_weekday_2', 'bin_weekday_3', 'bin_weekday_4', 'bin_weekday_5',\n",
       "       'bin_weekday_6', 'bin_weekday_7'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb529f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983417447728912"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2d7db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_auc\n",
      "Loading full dataset /mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv\n",
      "before nan drop: 41771\n",
      "after nan drop: 41771\n",
      "after dup. drop: 41684\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['index', 'y', 'x', 'dom_dir', 'dir_max', 'fire', 'weekday', 'month', 'band', 'firedate']\n",
      "Dropped columns ['bin_dir_max_7', 'bin_month_5', 'bin_dir_max_3', 'bin_weekday_4', 'bin_weekday_2', 'bin_corine_gr32', 'bin_corine_gr31', 'bin_dom_dir_7', 'bin_dir_max_4', 'bin_dir_max_6', 'bin_dir_max_8', 'bin_corine_gr24', 'bin_dom_dir_8', 'bin_dir_max_2', 'bin_dom_dir_2', 'bin_month_10', 'bin_dom_dir_6', 'bin_dom_dir_4', 'bin_dom_dir_3', 'bin_month_9', 'bin_dom_dir_5', 'bin_corine_gr23', 'bin_month_8', 'bin_month_4', 'bin_corine_gr1', 'bin_dir_max_1', 'bin_corine_gr4', 'bin_month_3', 'bin_dom_dir_1', 'bin_weekday_7', 'bin_month_6', 'bin_weekday_1', 'bin_weekday_6', 'bin_month_7', 'bin_weekday_5', 'pop', 'bin_weekday_3', 'bin_corine_gr33', 'bin_corine_gr5', 'bin_dir_max_5', 'bin_corine_gr21', 'bin_corine_gr22']\n",
      "1303/1303 [==============================] - 1s 922us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 967us/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 882us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 955us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 949us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 956us/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 800us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 946us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 3s 2ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 929us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 968us/step\n",
      "1303/1303 [==============================] - 1s 986us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 1ms/step\n",
      "1303/1303 [==============================] - 1s 876us/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 1s 883us/step\n",
      "1303/1303 [==============================] - 2s 2ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n",
      "1303/1303 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "rec1_scorer = make_scorer(recall_score, pos_label=1)\n",
    "rec0_scorer = make_scorer(recall_score, pos_label=0)\n",
    "results_lists={}\n",
    "scoring={'recall1':rec1_scorer, 'recall0':rec0_scorer}\n",
    "for modname in models:\n",
    "    print(modname)\n",
    "    #models[modname].fit(X,y)\n",
    "    #ypred=models['nn_auc'].predict(X)\n",
    "    X, y, g=load_dataset('/mnt/nvme2tb/ffp/datasets/train/train_new_sample_1_2_norm.csv', \\\n",
    "                          models[modname]['params']['feature_drop'])\n",
    "    r=permutation_importance(models[modname]['model'], X, y, n_repeats=1, scoring=scoring)\n",
    "    for s in scoring:\n",
    "        results_lists['%s %s'%(modname,s)]=[]\n",
    "        for i in r[s].importances_mean.argsort()[::-1]:\n",
    "            #if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            if not any(c in X.columns[i] for c in ['dir_max','dom_dir','wkd','month']):\n",
    "                results_dict={}\n",
    "                results_dict['rank %s %s'%(modname,s)]=X.columns[i]\n",
    "                results_dict['perm. imp. %s %s'%(modname,s)]=r[s].importances_mean[i]\n",
    "                results_lists['%s %s'%(modname,s)]+=[results_dict]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1412ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r=permutation_importance(sknnmodel, X, y, n_repeats=3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47df08ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "    #if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#    print(f\"{X.columns[i]:<17}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bf2d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pd=[]\n",
    "for mod in results_lists:\n",
    "    results_pd+=[pd.DataFrame(results_lists[mod])]\n",
    "all_res_pd=pd.concat(results_pd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "136940b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank nn_auc recall1</th>\n",
       "      <th>perm. imp. nn_auc recall1</th>\n",
       "      <th>rank nn_auc recall0</th>\n",
       "      <th>perm. imp. nn_auc recall0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>res_max</td>\n",
       "      <td>0.230714</td>\n",
       "      <td>bin_corine_28</td>\n",
       "      <td>0.055943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bin_corine_28</td>\n",
       "      <td>0.212473</td>\n",
       "      <td>bin_corine_26</td>\n",
       "      <td>0.042712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f81</td>\n",
       "      <td>0.205984</td>\n",
       "      <td>res_max</td>\n",
       "      <td>0.034084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ypos</td>\n",
       "      <td>0.141384</td>\n",
       "      <td>bin_corine_29</td>\n",
       "      <td>0.027792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bin_corine_26</td>\n",
       "      <td>0.122567</td>\n",
       "      <td>ypos</td>\n",
       "      <td>0.024232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xpos</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>xpos</td>\n",
       "      <td>0.023046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bin_corine_29</td>\n",
       "      <td>0.110743</td>\n",
       "      <td>bin_corine_21</td>\n",
       "      <td>0.020673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dem</td>\n",
       "      <td>0.106849</td>\n",
       "      <td>min_dew_temp</td>\n",
       "      <td>0.019810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dom_vel</td>\n",
       "      <td>0.106417</td>\n",
       "      <td>f81</td>\n",
       "      <td>0.019127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bin_corine_21</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>bin_corine_33</td>\n",
       "      <td>0.018264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>min_temp</td>\n",
       "      <td>0.079452</td>\n",
       "      <td>dem</td>\n",
       "      <td>0.018048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>road_dens</td>\n",
       "      <td>0.071089</td>\n",
       "      <td>dom_vel</td>\n",
       "      <td>0.017365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evi</td>\n",
       "      <td>0.069142</td>\n",
       "      <td>bin_corine_12</td>\n",
       "      <td>0.015172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rain_7_days</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>ndvi</td>\n",
       "      <td>0.014777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_temp</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>bin_corine_24</td>\n",
       "      <td>0.014525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bin_corine_17</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>bin_corine_17</td>\n",
       "      <td>0.014489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_dew_temp</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>bin_corine_23</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bin_corine_33</td>\n",
       "      <td>0.050036</td>\n",
       "      <td>bin_corine_20</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bin_corine_20</td>\n",
       "      <td>0.048882</td>\n",
       "      <td>bin_corine_25</td>\n",
       "      <td>0.012476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bin_corine_12</td>\n",
       "      <td>0.045710</td>\n",
       "      <td>bin_corine_32</td>\n",
       "      <td>0.010103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bin_corine_24</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>road_dens</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bin_corine_32</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>frequency</td>\n",
       "      <td>0.007946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>bin_corine_13</td>\n",
       "      <td>0.007946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ndvi</td>\n",
       "      <td>0.028623</td>\n",
       "      <td>aspect</td>\n",
       "      <td>0.007227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bin_corine_25</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>max_temp</td>\n",
       "      <td>0.004638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aspect</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>bin_corine_18</td>\n",
       "      <td>0.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bin_corine_18</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>lst_night</td>\n",
       "      <td>0.003236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mean_temp</td>\n",
       "      <td>0.015934</td>\n",
       "      <td>mean_dew_temp</td>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bin_corine_13</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>bin_corine_2</td>\n",
       "      <td>0.002301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bin_corine_23</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>max_dew_temp</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bin_corine_2</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>bin_corine_15</td>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bin_corine_44</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>bin_corine_27</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>max_dew_temp</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>bin_corine_16</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bin_corine_15</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>slope</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bin_corine_7</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>evi</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bin_corine_3</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>bin_corine_3</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lst_day</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>bin_corine_7</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bin_corine_16</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>rain_7_days</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bin_corine_31</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>lst_day</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>bin_corine_44</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank nn_auc recall1  perm. imp. nn_auc recall1 rank nn_auc recall0  \\\n",
       "0              res_max                   0.230714       bin_corine_28   \n",
       "1        bin_corine_28                   0.212473       bin_corine_26   \n",
       "2                  f81                   0.205984             res_max   \n",
       "3                 ypos                   0.141384       bin_corine_29   \n",
       "4        bin_corine_26                   0.122567                ypos   \n",
       "5                 xpos                   0.111319                xpos   \n",
       "6        bin_corine_29                   0.110743       bin_corine_21   \n",
       "7                  dem                   0.106849        min_dew_temp   \n",
       "8              dom_vel                   0.106417                 f81   \n",
       "9        bin_corine_21                   0.087311       bin_corine_33   \n",
       "10            min_temp                   0.079452                 dem   \n",
       "11           road_dens                   0.071089             dom_vel   \n",
       "12                 evi                   0.069142       bin_corine_12   \n",
       "13         rain_7_days                   0.058327                ndvi   \n",
       "14            max_temp                   0.057534       bin_corine_24   \n",
       "15       bin_corine_17                   0.056020       bin_corine_17   \n",
       "16        min_dew_temp                   0.053064       bin_corine_23   \n",
       "17       bin_corine_33                   0.050036       bin_corine_20   \n",
       "18       bin_corine_20                   0.048882       bin_corine_25   \n",
       "19       bin_corine_12                   0.045710       bin_corine_32   \n",
       "20       bin_corine_24                   0.039005           road_dens   \n",
       "21       bin_corine_32                   0.032372           frequency   \n",
       "22           frequency                   0.030570       bin_corine_13   \n",
       "23                ndvi                   0.028623              aspect   \n",
       "24       bin_corine_25                   0.026388            max_temp   \n",
       "25              aspect                   0.026099       bin_corine_18   \n",
       "26       bin_corine_18                   0.025667           lst_night   \n",
       "27           mean_temp                   0.015934       mean_dew_temp   \n",
       "28       bin_corine_13                   0.014636        bin_corine_2   \n",
       "29       bin_corine_23                   0.013122        max_dew_temp   \n",
       "30        bin_corine_2                   0.011031       bin_corine_15   \n",
       "31       bin_corine_44                   0.005984       bin_corine_27   \n",
       "32        max_dew_temp                   0.005479       bin_corine_16   \n",
       "33       bin_corine_15                   0.005119               slope   \n",
       "34        bin_corine_7                   0.005047                 evi   \n",
       "35        bin_corine_3                   0.004903        bin_corine_3   \n",
       "36             lst_day                   0.004686        bin_corine_7   \n",
       "37       bin_corine_16                   0.004686         rain_7_days   \n",
       "38       bin_corine_31                   0.004614             lst_day   \n",
       "39               slope                   0.004398       bin_corine_44   \n",
       "\n",
       "    perm. imp. nn_auc recall0  \n",
       "0                    0.055943  \n",
       "1                    0.042712  \n",
       "2                    0.034084  \n",
       "3                    0.027792  \n",
       "4                    0.024232  \n",
       "5                    0.023046  \n",
       "6                    0.020673  \n",
       "7                    0.019810  \n",
       "8                    0.019127  \n",
       "9                    0.018264  \n",
       "10                   0.018048  \n",
       "11                   0.017365  \n",
       "12                   0.015172  \n",
       "13                   0.014777  \n",
       "14                   0.014525  \n",
       "15                   0.014489  \n",
       "16                   0.013986  \n",
       "17                   0.013986  \n",
       "18                   0.012476  \n",
       "19                   0.010103  \n",
       "20                   0.008485  \n",
       "21                   0.007946  \n",
       "22                   0.007946  \n",
       "23                   0.007227  \n",
       "24                   0.004638  \n",
       "25                   0.003416  \n",
       "26                   0.003236  \n",
       "27                   0.002768  \n",
       "28                   0.002301  \n",
       "29                   0.002121  \n",
       "30                   0.001654  \n",
       "31                   0.001402  \n",
       "32                   0.001150  \n",
       "33                   0.001007  \n",
       "34                   0.000971  \n",
       "35                   0.000899  \n",
       "36                   0.000863  \n",
       "37                   0.000827  \n",
       "38                   0.000539  \n",
       "39                   0.000539  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res_pd.iloc[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97651e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_pd.to_csv('results/permimpall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73061ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
