{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.metrics\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from MLscores import calc_metrics, metrics_dict, cmvals, recall, hybridrecall\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.inspection import permutation_importance\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ba14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NN_model(params, X):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    n_features = X.shape[1]\n",
    "    intlayers = int(params['n_internal_layers'][0])\n",
    "    model.add(Dense(params['n_internal_layers'][1]['layer_1_' + str(intlayers) + '_nodes'], activation='relu'))#, input_shape=(n_features,))) \n",
    "    if not params['dropout'] is None:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    for i in range(2, intlayers + 2):\n",
    "        model.add(Dense(int(params['n_internal_layers'][1]['layer_' + str(i) + '_' + str(intlayers) + '_nodes']),\n",
    "                        activation='relu', )) #kernel_initializer=initializer))\n",
    "        if not params['dropout'] is None:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    if params['optimizer']['name']=='Adam':\n",
    "        if params['optimizer']['adam_params'] is None:\n",
    "            opt = Adam()\n",
    "        else:\n",
    "            opt = Adam(learning_rate=params['optimizer']['adam_params']['learning_rate_adam'], beta_1=params['optimizer']['adam_params']['beta_1'],\n",
    "                       beta_2=params['optimizer']['adam_params']['beta_2'],amsgrad=params['optimizer']['adam_params']['amsgrad'])\n",
    "    elif params['optimizer']['name']=='SGD':\n",
    "        opt = SGD(learning_rate=params['optimizer']['learning_rate_SGD'])\n",
    "\n",
    "    if params['metric'] == 'accuracy':\n",
    "        metrics = ['accuracy']\n",
    "    elif params['metric'] == 'sparse':\n",
    "        metrics = [tensorflow.metrics.SparseCategoricalAccuracy()]\n",
    "    elif params['metric'] == 'tn':\n",
    "        metrics = [tensorflow.metrics.TrueNegatives(),tensorflow.metrics.TruePositives()]\n",
    "    if 'loss' in params and params['loss'] == 'unbalanced':\n",
    "        lossf=unbalanced_loss\n",
    "    else:\n",
    "        lossf='sparse_categorical_crossentropy'\n",
    "    model.compile(optimizer=opt, loss=lossf, metrics=metrics)  # , AUC(multi_label=False)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f862423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(trfiles, featuredrop=[], debug=True, returnid=False):\n",
    "    # dsfile = 'dataset_ndvi_lu.csv'\n",
    "    domdircheck = 'dom_dir'\n",
    "    dirmaxcheck = 'dir_max'\n",
    "    corinecheck = 'Corine'\n",
    "    monthcheck = 'month'\n",
    "    wkdcheck = 'wkd'\n",
    "    firedatecheck = 'firedate'\n",
    "    X_columns = ['max_temp', 'min_temp', 'mean_temp', 'res_max', dirmaxcheck, 'dom_vel', domdircheck,\n",
    "                 'rain_7days', corinecheck, 'Slope', 'DEM', 'Curvature', 'Aspect', 'ndvi', 'evi', 'lst_day',\n",
    "                 'lst_night', monthcheck, wkdcheck,\n",
    "                 'mean_dew_temp', 'max_dew_temp', 'min_dew_temp','frequency', 'f81', 'x', 'y']\n",
    "    y_columns = ['fire']\n",
    "    # if not os.path.exists(os.path.join(dsetfolder, dsready)):\n",
    "    if isinstance(trfiles, list):\n",
    "        if debug:\n",
    "            print(\"Loading full dataset ...\")\n",
    "        dflist=[]\n",
    "        for dsfile in trfiles:\n",
    "            if debug:\n",
    "                print(\"Loading dataset file %s\" % dsfile)\n",
    "            dflist.append(pd.read_csv(dsfile))\n",
    "        df = pd.concat(dflist)\n",
    "    else:\n",
    "        dsfile = trfiles\n",
    "    df = pd.read_csv(dsfile)\n",
    "    X_columns_upper = [c.upper() for c in X_columns]\n",
    "    newcols = [c for c in df.columns if\n",
    "               c.upper() in X_columns_upper or any([cX in c.upper() for cX in X_columns_upper])]\n",
    "    X_columns = newcols\n",
    "    #corine_col, newcols = check_categorical(df, corinecheck, newcols)\n",
    "    #dirmax_col, newcols = check_categorical(df, dirmaxcheck, newcols)\n",
    "    #domdir_col, newcols = check_categorical(df, domdircheck, newcols)\n",
    "    #month_col, newcols = check_categorical(df, monthcheck, newcols)\n",
    "    #wkd_col, newcols = check_categorical(df, wkdcheck, newcols)\n",
    "\n",
    "    firedate_col = [c for c in df.columns if firedatecheck.upper() in c.upper()][0]\n",
    "    X, y, groupspd = prepare_dataset(df, X_columns, y_columns, firedate_col)\n",
    "    print(\"Ignored columns from csv %s\"%([c for c in df.columns if c not in X.columns]))\n",
    "    idpd = df['id']\n",
    "    df = None\n",
    "    X_columns = X.columns\n",
    "    if len(featuredrop) > 0:\n",
    "        X = X.drop(columns=[c for c in X.columns if any([fd in c for fd in featuredrop])])\n",
    "    print(\"Dropped columns %s\"%(list(set(X_columns)-set(X.columns))))\n",
    "\n",
    "    #if debug:\n",
    "    #    print(\"X helth check %s\"%X.describe())\n",
    "    #    print(\"y helth check %s\"%y.describe())\n",
    "    if returnid:\n",
    "        return X, y, groupspd, idpd\n",
    "    else:\n",
    "        return X, y, groupspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eee8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, X_columns, y_columns, firedate_col):\n",
    "    df = df[X_columns+y_columns+[firedate_col]]\n",
    "    print('before nan drop: %d' % len(df.index))\n",
    "    df = df.dropna()\n",
    "    print('after nan drop: %d' % len(df.index))\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    print('after dup. drop: %d' % len(df.index))\n",
    "    print('renaming \"x\": \"xpos\", \"y\": \"ypos\"')\n",
    "    X_unnorm, y_int = df[X_columns], df[y_columns]\n",
    "    X_unnorm = X_unnorm.rename(columns={'x': 'xpos', 'y': 'ypos'})\n",
    "    # X = normdataset.normalize_dataset(X_unnorm, aggrfile='stats/featurestats.json')\n",
    "    X = X_unnorm\n",
    "    y = y_int\n",
    "    groupspd = df[firedate_col]\n",
    "    return X, y, groupspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params={'ES_mindelta': 0.001, 'ES_monitor': 'loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 10}, 'dropout': 0.1, 'feature_drop': ('dir_max', 'dom_dir', 'month', 'wkd'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 70}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}\n",
    "params={'ES_mindelta': 0.0001, 'ES_monitor': 'loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 5}, 'dropout': 0.3, 'feature_drop': ('dir_max', 'dom_dir', 'month', 'wkd'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 200.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85ecfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 25793\n",
      "after nan drop: 25757\n",
      "after dup. drop: 23813\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['id', 'firedate', 'Unnamed: 0', 'Unnamed: 0.1', 'fire', 'x', 'y', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1']\n",
      "Dropped columns []\n"
     ]
    }
   ],
   "source": [
    "#X, y, g=load_dataset('/home/aapostolakis/Documents/ffpdata/newcrossval/datasets/randomnofire/old_random_new_features_norm.csv',\\\n",
    "#                    featuredrop=params['feature_drop'])\n",
    "X, y, g=load_dataset('/home/aapostolakis/Documents/ffpdata/newcrossval/datasets/randomnofire/oldrandomnewfeat.csv')#,\\\n",
    "                    #featuredrop=params['feature_drop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eeb7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeModel(object):\n",
    "\n",
    "    def __init__(self, X=None, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return y_pred\n",
    "        #return np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        skwrapped_model = KerasClassifier(build_fn=creatennmodel,\n",
    "                                          train_input=X,\n",
    "                                          epochs=2,\n",
    "                                          batch_size=512,\n",
    "                                          #validation_split=1-TRAIN_TEST_SPLIT,\n",
    "                                          verbose=1)\n",
    "        self.model = skwrapped_model\n",
    "        self.model.fit(X, y)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93e4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "creatennmodel = partial(create_NN_model, params, X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a0c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor=params['ES_monitor'], patience=params['ES_patience'], min_delta=params['ES_mindelta'])\n",
    "#sknnmodel = KerasClassifier(build_fn=creatennmodel, batch_size=params['batch_size'], epochs=params['max_epochs'], verbose=1, callbacks=[es],\n",
    "#                            class_weight=params['class_weights'])\n",
    "es = EarlyStopping(monitor=params['ES_monitor'], patience=params['ES_patience'], min_delta=params['ES_mindelta'])\n",
    "sknnmodel = KerasClassifier(build_fn=creatennmodel, batch_size=params['batch_size'], epochs=200, verbose=0,)\\\n",
    "                           #validation_data=(X_test, y_test)) #class_weight=params['class_weights'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1771c75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2be2f92ee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sknnmodel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c782d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aapostolakis/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sknnmodel.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42408ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs = SequentialFeatureSelector(sknnmodel, n_features_to_select=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25dda94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a08b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestfeatmask=sfs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a065493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfn=0\\nfor i in range(0,len(bestfeatmask)):\\n    if bestfeatmask[i]:\\n        fn+=1  \\n        print('feature %d : %s'%(fn, X.columns[i]))\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fn=0\n",
    "for i in range(0,len(bestfeatmask)):\n",
    "    if bestfeatmask[i]:\n",
    "        fn+=1  \n",
    "        print('feature %d : %s'%(fn, X.columns[i]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1412ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=permutation_importance(sknnmodel, X, y, n_repeats=3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47df08ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom_vel          0.111 +/- 0.002\n",
      "evi              0.050 +/- 0.000\n",
      "f81              0.045 +/- 0.001\n",
      "xpos             0.030 +/- 0.001\n",
      "ypos             0.027 +/- 0.001\n",
      "month_8          0.023 +/- 0.001\n",
      "dem              0.022 +/- 0.001\n",
      "dom_dir_2        0.020 +/- 0.000\n",
      "dom_dir_1        0.020 +/- 0.001\n",
      "dir_max_1        0.019 +/- 0.001\n",
      "month_7          0.019 +/- 0.000\n",
      "wkd_3            0.018 +/- 0.001\n",
      "dir_max_7        0.018 +/- 0.000\n",
      "dom_dir_8        0.017 +/- 0.000\n",
      "dir_max_8        0.017 +/- 0.001\n",
      "dir_max_2        0.016 +/- 0.001\n",
      "wkd_6            0.016 +/- 0.000\n",
      "dir_max_6        0.016 +/- 0.001\n",
      "dir_max_3        0.016 +/- 0.001\n",
      "wkd_5            0.016 +/- 0.000\n",
      "wkd_2            0.016 +/- 0.001\n",
      "dom_dir_7        0.014 +/- 0.001\n",
      "wkd_1            0.014 +/- 0.001\n",
      "wkd_0            0.013 +/- 0.001\n",
      "month_9          0.013 +/- 0.000\n",
      "wkd_4            0.012 +/- 0.000\n",
      "max_temp         0.012 +/- 0.001\n",
      "dir_max_4        0.010 +/- 0.000\n",
      "month_6          0.010 +/- 0.000\n",
      "res_max          0.010 +/- 0.001\n",
      "corine_334       0.010 +/- 0.000\n",
      "dom_dir_3        0.009 +/- 0.000\n",
      "corine_323       0.008 +/- 0.001\n",
      "rain_7days       0.007 +/- 0.001\n",
      "frequency        0.007 +/- 0.001\n",
      "dom_dir_6        0.006 +/- 0.000\n",
      "corine_312       0.006 +/- 0.000\n",
      "dom_dir_5        0.006 +/- 0.000\n",
      "dir_max_5        0.006 +/- 0.000\n",
      "corine_243       0.006 +/- 0.001\n",
      "corine_324       0.006 +/- 0.000\n",
      "mean_temp        0.006 +/- 0.000\n",
      "dom_dir_4        0.005 +/- 0.000\n",
      "corine_313       0.005 +/- 0.000\n",
      "corine_311       0.004 +/- 0.000\n",
      "corine_321       0.004 +/- 0.000\n",
      "aspect           0.004 +/- 0.000\n",
      "slope            0.004 +/- 0.001\n",
      "corine_333       0.004 +/- 0.000\n",
      "month_4          0.003 +/- 0.000\n",
      "min_dew_temp     0.003 +/- 0.001\n",
      "mean_dew_temp    0.003 +/- 0.000\n",
      "ndvi_new         0.003 +/- 0.000\n",
      "month_5          0.002 +/- 0.000\n",
      "corine_211       0.002 +/- 0.000\n",
      "lst_night        0.002 +/- 0.000\n",
      "corine_223       0.002 +/- 0.000\n",
      "curvature        0.002 +/- 0.000\n",
      "corine_231       0.001 +/- 0.000\n",
      "corine_242       0.001 +/- 0.000\n",
      "min_temp         0.001 +/- 0.000\n",
      "max_dew_temp     0.001 +/- 0.000\n",
      "corine_322       0.001 +/- 0.000\n",
      "corine_112       0.001 +/- 0.000\n",
      "corine_142       0.000 +/- 0.000\n",
      "corine_332       0.000 +/- 0.000\n",
      "corine_411       0.000 +/- 0.000\n",
      "corine_131       0.000 +/- 0.000\n",
      "corine_221       0.000 +/- 0.000\n",
      "corine_133       0.000 +/- 0.000\n",
      "corine_212       0.000 +/- 0.000\n",
      "corine_121       0.000 +/- 0.000\n",
      "corine_421       0.000 +/- 0.000\n",
      "corine_122       0.000 +/- 0.000\n",
      "corine_512       0.000 +/- 0.000\n",
      "corine_222       0.000 +/- 0.000\n",
      "corine_331       0.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X.columns[i]:<17}\"\n",
    "            f\"{r.importances_mean[i]:.3f}\"\n",
    "            f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c19ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
