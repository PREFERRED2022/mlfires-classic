{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f0bdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nppar\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import datatable as dt\n",
    "import time\n",
    "import xarray\n",
    "import os\n",
    "import fileutils\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import random\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Array, Process, Manager\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187c25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridinfo():\n",
    "    rdiff=2227\n",
    "    minnorth=333237\n",
    "    #maxwest=1160624\n",
    "    minwest=1156167\n",
    "    maxeast=2747676\n",
    "    maxsouth=3504175\n",
    "    gridwidth=((maxeast-minwest) % rdiff) + 1\n",
    "    firstid = minwest-math.ceil((minwest-minnorth) / rdiff)*rdiff\n",
    "    gridheight=math.ceil((maxsouth-firstid) / rdiff)\n",
    "    return rdiff, firstid, gridwidth, gridheight\n",
    "\n",
    "def walkmonthdays(sfolder):\n",
    "    #sfolder = '/data2/ffp/datasets/daily/2015/08'\n",
    "    exfeat = [\"id\", \"firedate\"]\n",
    "    dayfiles=[]\n",
    "    for dayf in fileutils.find_files(sfolder, '*_norm.csv', listtype=\"walk\"):\n",
    "        dayfiles+=[dayf]\n",
    "        #print(fday)\n",
    "        '''\n",
    "        try:\n",
    "            #fday = '/data2/ffp/datasets/daily/2021/08/20210804_norm.csv'\n",
    "            creategrid_xs(fday, rdiff, firstid, gridwidth, gridheight)\n",
    "        except:\n",
    "            print(\"Fail to convert %s\"%fday)\n",
    "            traceback.print_exc()\n",
    "        '''\n",
    "    return dayfiles\n",
    "\n",
    "def call_creategrid(fday):\n",
    "    creategrid_xs(fday, rdiff, firstid, gridwidth, gridheight)\n",
    "\n",
    "def printduration(start, mess=''):\n",
    "    duration = time.time() - start\n",
    "    start = time.time()\n",
    "    print(\"Duration %s %.1f\" % (mess,duration))\n",
    "    return start\n",
    "\n",
    "def fill_grid_from_dict_np(_id, ggrid, firstid, iddict, rdiff, field=\"id\"):\n",
    "    print(_id)\n",
    "    try:\n",
    "        row,col = get_grid_xy(_id, firstid, rdiff)\n",
    "        print(row,col)\n",
    "        print(ggrid)\n",
    "        if field==\"id\":\n",
    "            ggrid[row,col]=_id\n",
    "        elif field==\"array\":\n",
    "            ggrid[row,col]=iddict[_id]\n",
    "    except:\n",
    "        print('dict: %s'%iddict[_id])\n",
    "\n",
    "def fill_grid_from_dict_np(_id, ggrid, firstid, iddict, rdiff, field=\"id\"):\n",
    "    print(_id)\n",
    "    try:\n",
    "        row,col = get_grid_xy(_id, firstid, rdiff)\n",
    "        print(row,col)\n",
    "        print(ggrid)\n",
    "        if field==\"id\":\n",
    "            ggrid[row,col]=_id\n",
    "        elif field==\"array\":\n",
    "            ggrid[row,col]=iddict[_id]\n",
    "    except:\n",
    "        print('dict: %s'%iddict[_id])\n",
    "\n",
    "\n",
    "def get_grid_xy(firstid, rdiff, _id,):\n",
    "    row =int((_id-firstid)/rdiff)\n",
    "    col = int(_id-firstid-rdiff*row)\n",
    "    return row,col\n",
    "\n",
    "def creategrid_np(fday, exfeat):\n",
    "    rdiff, firstid, gridwidth, gridheight = gridinfo()\n",
    "    start = time.time()\n",
    "    #daydict, featcolumns = loaddaydict(fday, exfeat,100)\n",
    "    #featn=len(featcolumns)\n",
    "    start = printduration(start, \"of loading day:\")\n",
    "    ggrid_id = np.zeros((gridwidth, gridheight))\n",
    "    #ggrid_patchpool = np.zeros((gridheight, gridwidth, featn))\n",
    "    #idsnp = np.array(list(daydict.keys()))\n",
    "    fill_grid_from_dict_v=np.vectorize(fill_grid_from_dict_np, excluded=[\"ggrid\", \"firstid\", \"iddict\", \"rdiff\", \"field\"] )\n",
    "    print(type(ggrid_id))\n",
    "    fill_grid_from_dict_v(idsnp, ggrid_id, firstid, daydict, rdiff)\n",
    "    start = printduration(start, \"of filling grid ids:\")\n",
    "    #fill_grid_from_dict(ggrid_patchpool, firstid, daydict, rdiff, \"array\")\n",
    "    #start = printduration(start, \"of filling grid features:\")\n",
    "    return ggrid_id, ggrid_patchpool\n",
    "\n",
    "\n",
    "def creategrid_xa(rdiff, firstid, gridwidth, gridheight, fday):\n",
    "    #fday = '/data2/ffp/datasets/daily/2021/08/20210803_norm.csv'\n",
    "    dt_df = dt.fread(fday)\n",
    "    npday = dt_df[:, dt_df.names.index('id'):].to_numpy(dt.float32)\n",
    "\n",
    "    #start = time.time()\n",
    "    id2xy, grid = nppar.fillcube(7, npday, firstid, rdiff, gridwidth, gridheight)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    xaday = xarray.DataArray(data=grid, dims=[\"x\", \"y\", \"feature\"],\n",
    "                             coords=dict(x=range(gridwidth), y=range(gridheight), feature=range(len(dt_df.names) - 1)))\n",
    "\n",
    "    orig_path=os.path.dirname(fday)\n",
    "    fname = os.path.basename(fday)\n",
    "    xaday.to_dataset().to_netcdf(os.path.join(orig_path,\"%s_grid.nc\"%(fname[0:8])))\n",
    "\n",
    "def creategrid_xs(rdiff, firstid, gridwidth, gridheight, dayfile, cpus):\n",
    "    #fday = '/data2/ffp/datasets/daily/2021/08/20210803_norm.csv'\n",
    "    #print(\"processing day %s\" % dayfile)\n",
    "    try:\n",
    "        orig_path = os.path.dirname(dayfile)\n",
    "        fname = os.path.basename(dayfile)\n",
    "        daygrid=\"%s_grid.nc\" % (fname[0:8])\n",
    "        #if os.path.isfile(os.path.join(orig_path, daygrid)): return\n",
    "        dt_df = dt.fread(dayfile)\n",
    "        firstfeat=dt_df.names.index('id')\n",
    "        npday = dt_df[:, firstfeat:].to_numpy(dt.float32)\n",
    "\n",
    "        #start = time.time()\n",
    "        id2xy, grid = nppar.fillcube(cpus, npday, firstid, rdiff, gridwidth, gridheight)\n",
    "        #end = time.time()\n",
    "        #print(end - start)\n",
    "\n",
    "        vardict = {}\n",
    "        for i in range(firstfeat, len(dt_df.names)):\n",
    "            varname = dt_df.names[i]\n",
    "            if dt_df.names[i] == 'x' or dt_df.names[i] == 'y':\n",
    "                varname = '%spos' % varname\n",
    "            vardict[varname] = ([\"x\", \"y\", \"time\"], np.expand_dims(grid[:, :, i-firstfeat], axis=2))\n",
    "\n",
    "        t = datetime.strptime(os.path.basename(dayfile)[0:8], '%Y%m%d')\n",
    "        xsday = xarray.Dataset(data_vars=vardict, coords=dict(x=range(gridwidth), y=range(gridheight), time=[t]))\n",
    "        xsday.to_netcdf(os.path.join(orig_path, daygrid))\n",
    "        #print(\"Successfull convertion %s\" % dayfile)\n",
    "    except:\n",
    "        print(\"Fail to convert %s\" % dayfile)\n",
    "        traceback.print_exc()\n",
    "        with open(\"/data2/ffp/datasets/daily/failedgrids.log\", \"a\") as f:\n",
    "            f.write(dayfile)\n",
    "\n",
    "def creategrid_xs_small(rdiff, firstid, gridwidth, gridheight, dayfile, pcpus, ccpus):\n",
    "    # fday = '/data2/ffp/datasets/daily/2021/08/20210803_norm.csv'\n",
    "    #print(\"processing day %s\" % dayfile)\n",
    "    try:\n",
    "        orig_path = os.path.dirname(dayfile)\n",
    "        fname = os.path.basename(dayfile)\n",
    "        daygrid = \"%s_grid.nc\" % (fname[0:8])\n",
    "        #if os.path.isfile(os.path.join(orig_path, daygrid)): return\n",
    "        dt_df = dt.fread(dayfile, nthreads=1)#pcpus)\n",
    "        firstfeat = dt_df.names.index('id')\n",
    "        #npday = dt_df[:, firstfeat:].to_numpy(dt.float32)\n",
    "\n",
    "        dynamic_feat=['id', 'max_temp', 'min_temp', 'mean_temp', 'res_max',\n",
    "         'dom_vel', 'rain_7days', #'dem', 'slope', 'curvature', 'aspect',\n",
    "         'ndvi_new', 'evi', 'lst_day', 'lst_night', 'max_dew_temp',\n",
    "         'mean_dew_temp', 'min_dew_temp', 'fire', 'dir_max_1', 'dir_max_2',\n",
    "         'dir_max_3', 'dir_max_4', 'dir_max_5', 'dir_max_6', 'dir_max_7',\n",
    "         'dir_max_8', 'dom_dir_1', 'dom_dir_2', 'dom_dir_3', 'dom_dir_4',\n",
    "         'dom_dir_5', 'dom_dir_6', 'dom_dir_7', 'dom_dir_8', #'corine_111',\n",
    "        # 'corine_112', 'corine_121', 'corine_122', 'corine_123', 'corine_124',\n",
    "        # 'corine_131', 'corine_132', 'corine_133', 'corine_141', 'corine_142',\n",
    "        # 'corine_211', 'corine_212', 'corine_213', 'corine_221', 'corine_222',\n",
    "        # 'corine_223', 'corine_231', 'corine_241', 'corine_242', 'corine_243',\n",
    "        # 'corine_244', 'corine_311', 'corine_312', 'corine_313', 'corine_321',\n",
    "        # 'corine_322', 'corine_323', 'corine_324', 'corine_331', 'corine_332',\n",
    "        # 'corine_333', 'corine_334', 'corine_411', 'corine_412', 'corine_421',\n",
    "        # 'corine_422', 'corine_511', 'corine_512', 'corine_521', 'wkd_0',\n",
    "        # 'wkd_1', 'wkd_2', 'wkd_3', 'wkd_4', 'wkd_5', 'wkd_6', 'month_7',\n",
    "        # 'month_4', 'month_5', 'month_6', 'month_8', 'month_9',\n",
    "        'frequency','f81',]# 'xpos', 'ypos']\n",
    "\n",
    "        dyn_df = dt_df[:, dynamic_feat]\n",
    "        npday = dyn_df.to_numpy(dt.float32)\n",
    "\n",
    "        # start = time.time()\n",
    "        id2xy, grid = nppar.fillcube(ccpus, npday, firstid, rdiff, gridwidth, gridheight)\n",
    "        # end = time.time()\n",
    "        # print(end - start)\n",
    "\n",
    "        vardict = {}\n",
    "        for i in range(0, len(dyn_df.names)):\n",
    "            varname = dyn_df.names[i]\n",
    "            if dyn_df.names[i] == 'x' or dyn_df.names[i] == 'y':\n",
    "                varname = '%spos' % varname\n",
    "            vardict[varname] = ([\"x\", \"y\", \"time\"], np.expand_dims(grid[:, :, i], axis=2))\n",
    "\n",
    "        t = datetime.strptime(os.path.basename(dayfile)[0:8], '%Y%m%d')\n",
    "        xsday = xarray.Dataset(data_vars=vardict, coords=dict(x=range(gridwidth), y=range(gridheight), time=[t]))\n",
    "        xsday.to_netcdf(os.path.join(orig_path, daygrid))\n",
    "        #print(\"Successfull convertion %s\" % dayfile)\n",
    "    except:\n",
    "        print(\"Fail to convert %s\" % dayfile)\n",
    "        traceback.print_exc()\n",
    "        with open(\"/data2/ffp/datasets/daily/failedgrids.log\", \"a\") as f:\n",
    "            f.write(dayfile)\n",
    "\n",
    "\n",
    "def create_xs_files(creategrid, days, pcpus, ccpus):\n",
    "    procs=[]\n",
    "    dayscompleted=[]\n",
    "    for cpu in range(pcpus):\n",
    "        d=days.pop()\n",
    "        dayscompleted+=[d]\n",
    "        procs += [Process(target=creategrid, args=(d,pcpus,ccpus))]\n",
    "        procs[cpu].start()\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        for p in procs:\n",
    "            if not p.is_alive():\n",
    "                procs.remove(p)\n",
    "        if len(procs)<pcpus:\n",
    "            if len(days)==0: break\n",
    "            d = days.pop()\n",
    "            dayscompleted += [d]\n",
    "            procs += [Process(target=creategrid, args=(d,pcpus,ccpus))]\n",
    "            procs[-1].start()\n",
    "\n",
    "def assignrow(ggrid, tabrow):\n",
    "    row, col = get_xy(tabrow[0])\n",
    "    ggrid[row, col, :]=tabrow[:]\n",
    "\n",
    "def assignrowshared(ggrid_sh, grid_shape, tabrows):\n",
    "    for i in range(tabrows.shape[0]):\n",
    "        tabrow=tabrows[i,:]\n",
    "        try:\n",
    "            row, col = get_xy(tabrow[0])\n",
    "            idx = row*grid_shape[1]*grid_shape[2]+col*grid_shape[2]\n",
    "            ggrid_sh[idx:idx+grid_shape[2]]=tabrow[:]\n",
    "        except:\n",
    "            \"Error row: %s\\n\"%i+traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ea0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max cpu count 16\n",
      "array rows: 372918\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "rdiff, firstid, gridwidth, gridheight = gridinfo()\n",
    "creategrid = partial(creategrid_xs_small, rdiff, firstid, gridwidth, gridheight)\n",
    "get_xy=partial(get_grid_xy, firstid, rdiff)\n",
    "dayfiles=walkmonthdays('/data2/ffp/datasets/daily/')\n",
    "fday='/data2/ffp/datasets/daily/2021/08/20210823_norm.csv'\n",
    "dt_df = dt.fread(fday)\n",
    "#creategrid_xs(rdiff, firstid, gridwidth, gridheight, fday)\n",
    "firstfeat=dt_df.names.index('id')\n",
    "npday = dt_df[:, firstfeat:].to_numpy(dt.float32)\n",
    "#npday = dt_df[:, 1:].to_numpy(dt.float32)\n",
    "maxcpus=multiprocessing.cpu_count()\n",
    "featn = len(dt_df[:, firstfeat:].names)\n",
    "ggrid = np.zeros((gridwidth, gridheight, featn))\n",
    "ggrid[:,:]=np.nan\n",
    "assignr=partial(assignrow, ggrid)\n",
    "#assignr(list(npday)[0])\n",
    "print('max cpu count %s'%maxcpus)\n",
    "print('array rows: %s'%npday.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ab5dc9",
   "metadata": {},
   "source": [
    "### Simple python run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ad72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.80 sec\n"
     ]
    }
   ],
   "source": [
    "nruns=1\n",
    "totalrun=0\n",
    "start = time.time()\n",
    "for i in range(npday.shape[0]):\n",
    "    assignr(npday[i])\n",
    "end = time.time()\n",
    "print('time: %.2f sec'%(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58872ea0",
   "metadata": {},
   "source": [
    "### Multiprocessing with map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e76ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time: 169.95 sec, cpus: 10\n"
     ]
    }
   ],
   "source": [
    "nruns=1\n",
    "totalrun=0\n",
    "npdayl=list(npday)\n",
    "for cpus in range(10,11):\n",
    "    for run in range(nruns):\n",
    "        start = time.time()\n",
    "        with Pool(cpus) as p:\n",
    "            p.map(assignr, npdayl)\n",
    "        end = time.time()\n",
    "        totalrun+=(end - start)\n",
    "    print('average time: %.2f sec, cpus: %s'%(totalrun/nruns, cpus))\n",
    "npdayl=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424386b2",
   "metadata": {},
   "source": [
    "### multiprocessing with shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401e5dbe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array rows: 372918\n",
      "time: 7.71 sec, cpu: 1\n",
      "time: 8.10 sec, cpu: 2\n",
      "time: 8.40 sec, cpu: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 225, in assignrowshared\n",
      "    row, col = get_xy(tabrow[0])\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 225, in assignrowshared\n",
      "    row, col = get_xy(tabrow[0])\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 67, in get_grid_xy\n",
      "    row =int((_id-firstid)/rdiff)\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 67, in get_grid_xy\n",
      "    row =int((_id-firstid)/rdiff)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-154:\n",
      "Process Process-155:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 225, in assignrowshared\n",
      "    row, col = get_xy(tabrow[0])\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 225, in assignrowshared\n",
      "    row, col = get_xy(tabrow[0])\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 67, in get_grid_xy\n",
      "    row =int((_id-firstid)/rdiff)\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 67, in get_grid_xy\n",
      "    row =int((_id-firstid)/rdiff)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 229, in assignrowshared\n",
      "    \"Error row: %s\\n\"%i+traceback.print_exc()\n",
      "TypeError: can only concatenate str (not \"NoneType\") to str\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 229, in assignrowshared\n",
      "    \"Error row: %s\\n\"%i+traceback.print_exc()\n",
      "TypeError: can only concatenate str (not \"NoneType\") to str\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 227, in assignrowshared\n",
      "    ggrid_sh[idx:idx+grid_shape[2]]=tabrow[:]\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/sharedctypes.py\", line 226, in __setitem__\n",
      "    with self:\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/sharedctypes.py\", line 193, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m procs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#while True:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#    time.sleep(1)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#    if all([not proc.is_alive() for proc in procs]):\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#        break\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m procs: p\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     21\u001b[0m shDay_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(shDay\u001b[38;5;241m.\u001b[39mget_obj(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape((gridwidth, gridheight, featn))\n\u001b[1;32m     22\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Process Process-156:\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 227, in assignrowshared\n",
      "    ggrid_sh[idx:idx+grid_shape[2]]=tabrow[:]\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/sharedctypes.py\", line 226, in __setitem__\n",
      "    with self:\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/sharedctypes.py\", line 193, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data2/ffp/envs/ml_vm2/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-ad447073c9b3>\", line 229, in assignrowshared\n",
      "    \"Error row: %s\\n\"%i+traceback.print_exc()\n",
      "TypeError: can only concatenate str (not \"NoneType\") to str\n"
     ]
    }
   ],
   "source": [
    "nruns=1\n",
    "totalrun=0\n",
    "ncpus=10\n",
    "for ncpus in range(1,8):\n",
    "    start = time.time()\n",
    "    procs=[]\n",
    "    chunk = int(npday.shape[0] / ncpus)\n",
    "    chunk_rem = npday.shape[0] % ncpus\n",
    "    shDay = Array('f', gridwidth * gridheight * featn)\n",
    "    for cpu in range(ncpus-1):\n",
    "        procs += [Process(target=assignrowshared, args=(shDay, (gridwidth, gridheight, featn), npday[cpu*chunk:(cpu+1)*chunk]))]\n",
    "        procs[cpu].start()\n",
    "    procs += [Process(target=assignrowshared, args=(shDay, (gridwidth, gridheight, featn), npday[(ncpus-1)*chunk:]))]\n",
    "    procs[-1].start()\n",
    "    #while True:\n",
    "    #    time.sleep(1)\n",
    "    #    if all([not proc.is_alive() for proc in procs]):\n",
    "    #        break\n",
    "    for p in procs: p.join()\n",
    "    shDay_np = np.frombuffer(shDay.get_obj(), dtype=np.float32).reshape((gridwidth, gridheight, featn))\n",
    "    end = time.time()\n",
    "    print('time: %.2f sec, cpu: %s'%((end-start),ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca67c4",
   "metadata": {},
   "source": [
    "### cython (with shared memory) cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ed194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu changes, runs per experiment: 20\n",
      "average time: 0.62 sec, threads: 1\n",
      "average time: 0.43 sec, threads: 2\n",
      "average time: 0.36 sec, threads: 3\n",
      "average time: 0.33 sec, threads: 4\n",
      "average time: 0.30 sec, threads: 5\n",
      "average time: 0.33 sec, threads: 6\n",
      "average time: 0.32 sec, threads: 7\n",
      "average time: 0.31 sec, threads: 8\n",
      "average time: 0.27 sec, threads: 9\n",
      "average time: 0.26 sec, threads: 10\n",
      "average time: 0.27 sec, threads: 11\n",
      "average time: 0.26 sec, threads: 12\n",
      "average time: 0.26 sec, threads: 13\n",
      "average time: 0.26 sec, threads: 14\n",
      "average time: 0.25 sec, threads: 15\n",
      "average time: 0.25 sec, threads: 16\n"
     ]
    }
   ],
   "source": [
    "nruns=20\n",
    "print('cpu changes, runs per experiment: %s'%nruns)\n",
    "for nt in range(1,maxcpus+1):\n",
    "    totalrun = 0\n",
    "    for run in range(nruns):\n",
    "        start = time.time()\n",
    "        id2xy, grid = nppar.fillcube(nt, npday, firstid, rdiff, gridwidth, gridheight)\n",
    "        end = time.time()\n",
    "        totalrun+=(end - start)\n",
    "    print('average time: %.2f sec, threads: %s'%(totalrun/nruns,nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed3bd4",
   "metadata": {},
   "source": [
    "### cython (with shared memory) chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a21da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk changes\n",
      "rows / threads: 37292 threads: 10\n",
      "time: 0.32 chunk: 1\n",
      "time: 0.28 chunk: 10001\n",
      "time: 0.28 chunk: 20001\n",
      "time: 0.29 chunk: 30001\n",
      "time: 0.26 chunk: 40001\n",
      "time: 0.27 chunk: 50001\n",
      "time: 0.28 chunk: 60001\n",
      "time: 0.29 chunk: 70001\n",
      "time: 0.31 chunk: 80001\n",
      "time: 0.32 chunk: 90001\n",
      "time: 0.33 chunk: 100001\n",
      "time: 0.34 chunk: 110001\n",
      "time: 0.36 chunk: 120001\n",
      "time: 0.37 chunk: 130001\n",
      "time: 0.38 chunk: 140001\n",
      "time: 0.39 chunk: 150001\n",
      "time: 0.40 chunk: 160001\n",
      "time: 0.41 chunk: 170001\n",
      "time: 0.43 chunk: 180001\n",
      "time: 0.43 chunk: 190001\n",
      "time: 0.44 chunk: 200001\n",
      "time: 0.45 chunk: 210001\n",
      "time: 0.46 chunk: 220001\n",
      "time: 0.48 chunk: 230001\n",
      "time: 0.49 chunk: 240001\n",
      "time: 0.50 chunk: 250001\n",
      "time: 0.51 chunk: 260001\n",
      "time: 0.52 chunk: 270001\n",
      "time: 0.53 chunk: 280001\n",
      "time: 0.54 chunk: 290001\n",
      "time: 0.54 chunk: 300001\n",
      "time: 0.58 chunk: 310001\n",
      "time: 0.58 chunk: 320001\n",
      "time: 0.58 chunk: 330001\n",
      "time: 0.58 chunk: 340001\n",
      "time: 0.59 chunk: 350001\n",
      "time: 0.61 chunk: 360001\n",
      "time: 0.62 chunk: 370001\n",
      "time: 0.63 chunk: 380001\n",
      "time: 0.63 chunk: 390001\n"
     ]
    }
   ],
   "source": [
    "print('chunk changes')\n",
    "nt = 10\n",
    "print('rows / threads: %.0f threads: %s' % ((npday.shape[0] / nt),nt))\n",
    "nruns=20\n",
    "for cs in range(1,400000,10000):\n",
    "    totalrun = 0\n",
    "    for run in range(nruns):\n",
    "        start = time.time()\n",
    "        id2xy, grid = nppar.fillcube(nt, npday, firstid,  rdiff, gridwidth, gridheight, 'static', cs)\n",
    "        end = time.time()\n",
    "        totalrun+=(end - start)\n",
    "    print('average time: %.2f chunk: %s'%(totalrun/nruns, cs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80fef3",
   "metadata": {},
   "source": [
    "### cython (with shared memory) OpenMP schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 14\n",
    "nruns=30\n",
    "print('optimum rows / threads: %.0f, threads: %s, runs per experiment: %s' % ((npday.shape[0] / nt),nt, nruns))\n",
    "for i in range(3):\n",
    "    id2xy, grid = nppar.fillcube(nt, npday, firstid,  rdiff, gridwidth, gridheight, None)\n",
    "schedules = [None, 'static', 'dynamic', 'guided']\n",
    "random.shuffle(schedules)\n",
    "for schedule in schedules:\n",
    "    totalrun = 0\n",
    "    for run in range(nruns):\n",
    "        start = time.time()\n",
    "        id2xy, grid = nppar.fillcube(nt, npday, firstid,  rdiff, gridwidth, gridheight, schedule)\n",
    "        end = time.time()\n",
    "        totalrun+=(end - start)\n",
    "    print('average time: %.2f sec, schedule: %s'%(totalrun/nruns, schedule))\n",
    "\n",
    "#xaday=xarray.DataArray(data=grid, dims=[\"x\", \"y\", \"feature\"],  coords=dict(x=range(gridwidth), y=range(gridheight), feature=range(len(dt_df.names)-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24965b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.strptime(os.path.basename(fday)[0:8], '%Y%m%d')\n",
    "\n",
    "vardict={}\n",
    "for i in range(1,len(dt_df.names)):\n",
    "    varname=dt_df.names[i]\n",
    "    if dt_df.names[i]=='x' or dt_df.names[i]=='y':\n",
    "        varname='%spos'%varname\n",
    "    vardict[varname]=([\"x\", \"y\", \"time\"], np.expand_dims(grid[:, :, i - 1], axis=2))\n",
    "\n",
    "xsday=xarray.Dataset(data_vars=vardict, coords=dict(x=range(gridwidth), y=range(gridheight), time=[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665b00b",
   "metadata": {},
   "source": [
    "### Table Conversion plus IO read/write (csv to netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f30fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.37 sec, python threads 5, cython threads 5\n",
      "time: 28.71 sec, python threads 10, cython threads 5\n",
      "time: 38.52 sec, python threads 5, cython threads 10\n",
      "time: 22.45 sec, python threads 10, cython threads 10\n",
      "time: 23.47 sec, python threads 5, cython threads 15\n",
      "time: 21.46 sec, python threads 10, cython threads 15\n"
     ]
    }
   ],
   "source": [
    "nruns=1\n",
    "totalrun=0\n",
    "for ccpus in range(5,16,5):\n",
    "    for pcpus in range(5, 11, 5):\n",
    "        start = time.time()\n",
    "        create_xs_files(creategrid, dayfiles[:10], pcpus, ccpus)\n",
    "        end = time.time()\n",
    "        print('time: %.2f sec, python threads %s, cython threads %s' % (end - start, pcpus, ccpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99302cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
