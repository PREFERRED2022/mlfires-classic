{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56a4faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.metrics\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from MLscores import calc_metrics, metrics_dict, cmvals, recall, hybridrecall\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae9054be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NN_model(params, X):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    n_features = X.shape[1]\n",
    "    intlayers = int(params['n_internal_layers'][0])\n",
    "    model.add(Dense(params['n_internal_layers'][1]['layer_1_' + str(intlayers) + '_nodes'], activation='relu', input_shape=(n_features,))) #kernel_initializer=initializer))\n",
    "    if not params['dropout'] is None:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    for i in range(2, intlayers + 2):\n",
    "        model.add(Dense(int(params['n_internal_layers'][1]['layer_' + str(i) + '_' + str(intlayers) + '_nodes']),\n",
    "                        activation='relu', )) #kernel_initializer=initializer))\n",
    "        if not params['dropout'] is None:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    if params['optimizer']['name']=='Adam':\n",
    "        if params['optimizer']['adam_params'] is None:\n",
    "            opt = Adam()\n",
    "        else:\n",
    "            opt = Adam(learning_rate=params['optimizer']['adam_params']['learning_rate_adam'], beta_1=params['optimizer']['adam_params']['beta_1'],\n",
    "                       beta_2=params['optimizer']['adam_params']['beta_2'],amsgrad=params['optimizer']['adam_params']['amsgrad'])\n",
    "    elif params['optimizer']['name']=='SGD':\n",
    "        opt = SGD(learning_rate=params['optimizer']['learning_rate_SGD'])\n",
    "\n",
    "    if params['metric'] == 'accuracy':\n",
    "        metrics = ['accuracy']\n",
    "    elif params['metric'] == 'sparse':\n",
    "        metrics = [tensorflow.metrics.SparseCategoricalAccuracy()]\n",
    "    elif params['metric'] == 'tn':\n",
    "        metrics = [tensorflow.metrics.TrueNegatives(),tensorflow.metrics.TruePositives()]\n",
    "    if 'loss' in params and params['loss'] == 'unbalanced':\n",
    "        lossf=unbalanced_loss\n",
    "    else:\n",
    "        lossf='sparse_categorical_crossentropy'\n",
    "    model.compile(optimizer=opt, loss=lossf, metrics=metrics)  # , AUC(multi_label=False)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d626edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(trfiles, featuredrop=[], debug=True, returnid=False):\n",
    "    # dsfile = 'dataset_ndvi_lu.csv'\n",
    "    domdircheck = 'dom_dir'\n",
    "    dirmaxcheck = 'dir_max'\n",
    "    corinecheck = 'Corine'\n",
    "    monthcheck = 'month'\n",
    "    wkdcheck = 'wkd'\n",
    "    firedatecheck = 'firedate'\n",
    "    X_columns = ['max_temp', 'min_temp', 'mean_temp', 'res_max', dirmaxcheck, 'dom_vel', domdircheck,\n",
    "                 'rain_7days', corinecheck, 'Slope', 'DEM', 'Curvature', 'Aspect', 'ndvi', 'evi', 'lst_day',\n",
    "                 'lst_night', monthcheck, wkdcheck,\n",
    "                 'mean_dew_temp', 'max_dew_temp', 'min_dew_temp','frequency', 'f81', 'x', 'y']\n",
    "    y_columns = ['fire']\n",
    "    # if not os.path.exists(os.path.join(dsetfolder, dsready)):\n",
    "    if isinstance(trfiles, list):\n",
    "        if debug:\n",
    "            print(\"Loading full dataset ...\")\n",
    "        dflist=[]\n",
    "        for dsfile in trfiles:\n",
    "            if debug:\n",
    "                print(\"Loading dataset file %s\" % dsfile)\n",
    "            dflist.append(pd.read_csv(dsfile))\n",
    "        df = pd.concat(dflist)\n",
    "    else:\n",
    "        dsfile = trfiles\n",
    "    df = pd.read_csv(dsfile)\n",
    "    X_columns_upper = [c.upper() for c in X_columns]\n",
    "    newcols = [c for c in df.columns if\n",
    "               c.upper() in X_columns_upper or any([cX in c.upper() for cX in X_columns_upper])]\n",
    "    X_columns = newcols\n",
    "    #corine_col, newcols = check_categorical(df, corinecheck, newcols)\n",
    "    #dirmax_col, newcols = check_categorical(df, dirmaxcheck, newcols)\n",
    "    #domdir_col, newcols = check_categorical(df, domdircheck, newcols)\n",
    "    #month_col, newcols = check_categorical(df, monthcheck, newcols)\n",
    "    #wkd_col, newcols = check_categorical(df, wkdcheck, newcols)\n",
    "\n",
    "    firedate_col = [c for c in df.columns if firedatecheck.upper() in c.upper()][0]\n",
    "    X, y, groupspd = prepare_dataset(df, X_columns, y_columns, firedate_col)\n",
    "    print(\"Ignored columns from csv %s\"%([c for c in df.columns if c not in X.columns]))\n",
    "    idpd = df['id']\n",
    "    df = None\n",
    "    X_columns = X.columns\n",
    "    if len(featuredrop) > 0:\n",
    "        X = X.drop(columns=[c for c in X.columns if any([fd in c for fd in featuredrop])])\n",
    "    print(\"Dropped columns %s\"%(list(set(X_columns)-set(X.columns))))\n",
    "    #if debug:\n",
    "    #    print(\"X helth check %s\"%X.describe())\n",
    "    #    print(\"y helth check %s\"%y.describe())\n",
    "    if returnid:\n",
    "        return X, y, groupspd, idpd\n",
    "    else:\n",
    "        return X, y, groupspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a53abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, X_columns, y_columns, firedate_col):\n",
    "    df = df[X_columns+y_columns+[firedate_col]]\n",
    "    print('before nan drop: %d' % len(df.index))\n",
    "    df = df.dropna()\n",
    "    print('after nan drop: %d' % len(df.index))\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    print('after dup. drop: %d' % len(df.index))\n",
    "    print('renaming \"x\": \"xpos\", \"y\": \"ypos\"')\n",
    "    X_unnorm, y_int = df[X_columns], df[y_columns]\n",
    "    X_unnorm = X_unnorm.rename(columns={'x': 'xpos', 'y': 'ypos'})\n",
    "    # X = normdataset.normalize_dataset(X_unnorm, aggrfile='stats/featurestats.json')\n",
    "    X = X_unnorm\n",
    "    y = y_int\n",
    "    groupspd = df[firedate_col]\n",
    "    return X, y, groupspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86b7ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nan drop: 26504\n",
      "after nan drop: 26504\n",
      "after dup. drop: 26504\n",
      "renaming \"x\": \"xpos\", \"y\": \"ypos\"\n",
      "Ignored columns from csv ['id', 'firedate', 'fire', 'x', 'y']\n",
      "Dropped columns []\n"
     ]
    }
   ],
   "source": [
    "X, y, g=load_dataset('/home/aapostolakis/Documents/ffpdata/newcrossval/datasets/randomnofire/old_random_new_features_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af4d4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'ES_mindelta': 0.002, 'ES_monitor': 'loss', 'ES_patience': 10, 'batch_size': 512, 'class_weights': {0: 1, 1: 10}, 'dropout': 0.1, 'feature_drop': ('dir_max', 'dom_dir', 'month', 'wkd'), 'max_epochs': 2000, 'metric': 'accuracy', 'n_internal_layers': (0, {'layer_1_0_nodes': 70.0}), 'optimizer': {'adam_params': None, 'name': 'Adam'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3bc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = create_NN_model(params, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c015739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
